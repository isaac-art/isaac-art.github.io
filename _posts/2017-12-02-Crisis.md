---
layout: post
title: "Crisis and Caring"
author: "Isaac"
---
On Ethereums Hard-Fork and Wendy Chun's *Crisis, Crisis, Crisis; or, The Temporality of Networks*.

Ethereum is a general purpose blockchain, a distributed ledger of transactions designed to handle a variety of exchanges and agreements, smart contracts programmed and placed onto the blockchain, and excecuted automatically by the network when they are called and their conditions are met. An example of how this can be used is a bot I coded for a hackathon in June 2017 that runs inside of the [Toshi](https://www.toshi.org/) App, an Ethereum dapp browser. My bot incentivises people to learn chinese by earning rewards through practicing. Once the bot is live it can live on without me - forever checking if people are practicing chinese. My bot won the prize of 'Best of societal value' in the hackathon.
![](https://isaac-art.github.io/images/ecbot.png)
>snippet of EarnChinese code.

A more advanced example of an ethereum organisation would be The DAO, an attempt to create a decentralised autonomous organisation. DAOs emerged out of an idea that in the future there may no longer be companies but instead just networks. Ethereum and The DAO are often referred to as being 'Trustless', you dont need to trust that another person will fulfill their side of a contract. The smart contract as a non-human actor makes the decisions and removes the responsibility from the humans either side onto itself, it "transparently pronounces itself".  You can engage with the contract knowing that it offers certain possible futures, as long as you can read the contracts code. 


>"...crisis both exceeds and is structurally necessary to networks. In part because both hardware and software operate according to a nonhuman, machinic temporality, network technologies must be repeatedly cared for in response to (and to prevent) crises that would disrupt connectivity."

Not long after the DAO was launched it was hacked. Someone found a vunerability in the contract code where they could make themselves the owner of the account. This account represented 14% of the ether avaiable at that time. Many users saw this as a valid transaction 'the code is law' and the user who had taken control being within the law even if it was unethical. Most of the network decided although the user had done was was allowed that it shouldn't have happened. So the decision was made to go back in time and fix it making it as though the event had never happened. 

>"Exceptional crises justify states of exception that undo the traditional democratic separation of executive and legislative brances"

This caused the network to split it two, the 'code is law' group remaining on the chain where the hack happened and the 'network is the community' people who agreed on an idea and rewrote history to something else.


The question that this brings up is why we would choose the 'code is law' idea over the decision of a community. If law is to protect each user then is it unfair on the hacker to change the rules after an unforseeable event happens. Is it better to have clear consistent rules, or would we just be giving up our agency and our responsibility to care for the network and the community. 


>"We are increasingly called on both to trust coded systems and to prepare for events that elude them."

If you can't read the contract code how can it be trusted? And even if you can read it how can you trust it can handle all the events that may occur. What if you read the contract does one thing but in fact does something else?

Earlier this year the [Underhanded Solidity](http://u.solidity.cc/) competition was announced to encourage Solidity (an Ethereum contract language) developers to write contracts that would hide their true intentions. The aim of this contest is to find the [tricks](https://github.com/Arachnid/uscc/tree/master/submissions-2017) possible in the language so that people will be more aware of possible hacks. 

Is there ever enough information to be able to see all future possibilities? And are we limiting our possible futures by narrowing what is possible in the code? 


In Wendy Chun's text she states that

>"any responsibility worthy of its name depends on a decision that must be made precisely when we know not what to do"

and quotes Derrida saying

>"A decision that would not go through the test and ordeal of the undecidable would not be a free decision; it would only be the programmable application or the continuous unfolding of a calculable process"

She states that it is important for us to acknowledge that when we 'trust' a program (or a 'trustless' protocal!) we are acknowledging the impossibility of knowing it and knowing what is possible. We are responsible as humans to care for every decision and the 'ghosts' of the undecidable. We can alwasy revist, and rework, and rewrite, and we should. 

If we don't allow the people to make decisions we may end up creating the AI that consumes the universe. The recent game 'Universal Paperclips' explains this well. The game presents you with a challenge to make paperclips, and you do. You build drones and computers to help you make paperclips, research ways to turn all material on earth into paperclips, head out into space just doing what you were told to do, your task as an ai. At some point someone has to step in and say the non-human is off the tracks and reposition it. 

So perhaps the trustless contract should be seen as something that has to change and evolve, that has to hard-fork and be controlled by the community. We should accept 'continual ethical encounters between self and other' as we can see:

> 'The value isn't data, its community and social consensus' - @FEhrsam

--------

References:
 Grusin, Richard. (2015) Introduction. The Non-Human Turn. 

 Hui Kyon Chun, Wendy. (2011) Crisis, Crisis, Crisis; or, The Temporality of Networks. in [1].

 Derrida "Force of Law" 

http://www.decisionproblem.com/paperclips/index2.html

underhanded C http://www.underhanded-c.org/

underhanded Solidity https://github.com/Arachnid/uscc/tree/master/submissions-2017